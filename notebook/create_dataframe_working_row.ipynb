{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ad82314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62deed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e4154b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/21 09:18:45 WARN Utils: Your hostname, JosePC resolves to a loopback address: 127.0.1.1; using 192.168.15.30 instead (on interface wlo1)\n",
      "23/02/21 09:18:45 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/21 09:18:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/02/21 09:18:46 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/02/21 09:18:46 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "                    .master(\"local[1]\") \\\n",
    "                    .appName(\"\") \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d574c77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list = [(1, 'Scott'), (2, 'Donald'), (3, 'Mickey'), (4, 'Elvis')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "739630f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(user_list, 'user_id int, user_first_name string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c50f04fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 0) / 1]\r",
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+\n",
      "|user_id|user_first_name|\n",
      "+-------+---------------+\n",
      "|      1|          Scott|\n",
      "|      2|         Donald|\n",
      "|      3|         Mickey|\n",
      "|      4|          Elvis|\n",
      "+-------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ce40afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(user_id=1, user_first_name='Scott'),\n",
       " Row(user_id=2, user_first_name='Donald'),\n",
       " Row(user_id=3, user_first_name='Mickey'),\n",
       " Row(user_id=4, user_first_name='Elvis')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "014e021c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bba8e4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bf7d1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Row in module pyspark.sql.types:\n",
      "\n",
      "class Row(builtins.tuple)\n",
      " |  Row(*args: Optional[str], **kwargs: Optional[Any]) -> 'Row'\n",
      " |  \n",
      " |  A row in :class:`DataFrame`.\n",
      " |  The fields in it can be accessed:\n",
      " |  \n",
      " |  * like attributes (``row.key``)\n",
      " |  * like dictionary values (``row[key]``)\n",
      " |  \n",
      " |  ``key in row`` will search through row keys.\n",
      " |  \n",
      " |  Row can be used to create a row object by using named arguments.\n",
      " |  It is not allowed to omit a named argument to represent that the value is\n",
      " |  None or missing. This should be explicitly set to None in this case.\n",
      " |  \n",
      " |  .. versionchanged:: 3.0.0\n",
      " |      Rows created from named arguments no longer have\n",
      " |      field names sorted alphabetically and will be ordered in the position as\n",
      " |      entered.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> row = Row(name=\"Alice\", age=11)\n",
      " |  >>> row\n",
      " |  Row(name='Alice', age=11)\n",
      " |  >>> row['name'], row['age']\n",
      " |  ('Alice', 11)\n",
      " |  >>> row.name, row.age\n",
      " |  ('Alice', 11)\n",
      " |  >>> 'name' in row\n",
      " |  True\n",
      " |  >>> 'wrong_key' in row\n",
      " |  False\n",
      " |  \n",
      " |  Row also can be used to create another Row like class, then it\n",
      " |  could be used to create Row objects, such as\n",
      " |  \n",
      " |  >>> Person = Row(\"name\", \"age\")\n",
      " |  >>> Person\n",
      " |  <Row('name', 'age')>\n",
      " |  >>> 'name' in Person\n",
      " |  True\n",
      " |  >>> 'wrong_key' in Person\n",
      " |  False\n",
      " |  >>> Person(\"Alice\", 11)\n",
      " |  Row(name='Alice', age=11)\n",
      " |  \n",
      " |  This form can also be used to create rows as tuple values, i.e. with unnamed\n",
      " |  fields.\n",
      " |  \n",
      " |  >>> row1 = Row(\"Alice\", 11)\n",
      " |  >>> row2 = Row(name=\"Alice\", age=11)\n",
      " |  >>> row1 == row2\n",
      " |  True\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Row\n",
      " |      builtins.tuple\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __call__(self, *args: Any) -> 'Row'\n",
      " |      create new Row object\n",
      " |  \n",
      " |  __contains__(self, item: Any) -> bool\n",
      " |      Return key in self.\n",
      " |  \n",
      " |  __getattr__(self, item: str) -> Any\n",
      " |  \n",
      " |  __getitem__(self, item: Any) -> Any\n",
      " |      Return self[key].\n",
      " |  \n",
      " |  __reduce__(self) -> Union[str, Tuple[Any, ...]]\n",
      " |      Returns a tuple so Python knows how to pickle Row.\n",
      " |  \n",
      " |  __repr__(self) -> str\n",
      " |      Printable representation of Row used in Python REPL.\n",
      " |  \n",
      " |  __setattr__(self, key: Any, value: Any) -> None\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  asDict(self, recursive: bool = False) -> Dict[str, Any]\n",
      " |      Return as a dict\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      recursive : bool, optional\n",
      " |          turns the nested Rows to dict (default: False).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If a row contains duplicate field names, e.g., the rows of a join\n",
      " |      between two :class:`DataFrame` that both have the fields of same names,\n",
      " |      one of the duplicate fields will be selected by ``asDict``. ``__getitem__``\n",
      " |      will also return one of the duplicate fields, however returned value might\n",
      " |      be different to ``asDict``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> Row(name=\"Alice\", age=11).asDict() == {'name': 'Alice', 'age': 11}\n",
      " |      True\n",
      " |      >>> row = Row(key=1, value=Row(name='a', age=2))\n",
      " |      >>> row.asDict() == {'key': 1, 'value': Row(name='a', age=2)}\n",
      " |      True\n",
      " |      >>> row.asDict(True) == {'key': 1, 'value': {'name': 'a', 'age': 2}}\n",
      " |      True\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(cls, *args: Optional[str], **kwargs: Optional[Any]) -> 'Row'\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from builtins.tuple:\n",
      " |  \n",
      " |  __add__(self, value, /)\n",
      " |      Return self+value.\n",
      " |  \n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __getnewargs__(self, /)\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __hash__(self, /)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __len__(self, /)\n",
      " |      Return len(self).\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __mul__(self, value, /)\n",
      " |      Return self*value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __rmul__(self, value, /)\n",
      " |      Return value*self.\n",
      " |  \n",
      " |  count(self, value, /)\n",
      " |      Return number of occurrences of value.\n",
      " |  \n",
      " |  index(self, value, start=0, stop=9223372036854775807, /)\n",
      " |      Return first index of value.\n",
      " |      \n",
      " |      Raises ValueError if the value is not present.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from builtins.tuple:\n",
      " |  \n",
      " |  __class_getitem__(...) from builtins.type\n",
      " |      See PEP 585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3323229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Row(\"Alice\", 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3da3857",
   "metadata": {},
   "outputs": [],
   "source": [
    "row2 = Row(name=\"Alice\", age=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db0b30cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(name='Alice', age=11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46678adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alice'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row2.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0ecd1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alice'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row2['name']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
